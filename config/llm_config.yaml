# LLM Configuration
llm:
  provider: "openai"  # openai, anthropic, gemini, grok, ollama
  model: "gpt-4"      # Model name for the provider
  api_key: ""         # Will be overridden by environment variable
  base_url: ""        # Optional: Custom base URL
  timeout: 30         # Request timeout in seconds

# Server Configuration
server:
  host: "localhost"
  port: 8000
  debug: false

# Logging Configuration
logging:
  level: "INFO"       # DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/database_agent.log"

# Security Configuration
security:
  enable_audit_logging: true
  mask_sensitive_data: true 